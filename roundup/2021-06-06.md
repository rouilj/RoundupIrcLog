# Roundup IRC Log for 2021-06-06 #
# Roundup IRC Log for 2021-06-06
* <a href="#04:31.42" id="04:31.42">04:31.42 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: rouilj: I'm looking at a few examples now:
* <a href="#04:32.44" id="04:32.44">04:32.44 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: one case: two entries both with __retired__=True, ordering has the higher id before the lower id
* <a href="#04:34.29" id="04:34.29">04:34.29 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: another case (this is a spammer so we don't actually care about it): 6 entries, 5 __retired__=True then 1 __retired__=False. Ids are 2039,2583,2580,2581,2584,2600
* <a href="#04:34.56" id="04:34.56">04:34.56 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: if I understand you correctly you think that sorting the csv by id might fix the problem in itself? I can try that easily.
* <a href="#04:42.38" id="04:42.38">04:42.38 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: new error (from 1.4.15 still):
* <a href="#04:42.47" id="04:42.47">04:42.47 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: KeyError: '(2005, 10, 29, 17, 28, 11.859999, 0, 0, 0)'
* <a href="#04:43.13" id="04:43.13">04:43.13 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: there are quite a lot of time entries with badly rounded FP numbers, dunno if it's something to do with that. I suspect more munging will be needed :-)
* <a href="#04:43.56" id="04:43.56">04:43.56 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: no, even 11.86 fails
* <a href="#04:46.04" id="04:46.04">04:46.04 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: and same error from 2.0.0
* <a href="#04:46.24" id="04:46.24">04:46.24 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: oh, wait, the sort will have screwed up the header
* <a href="#04:49.05" id="04:49.05">04:49.05 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: ok. Same UNIQUE constraint failure with the rows sorted by id (i.e. field 7 in the CSV, counting from 1)
* <a href="#04:49.16" id="04:49.16">04:49.16 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: with both 1.4.15 and 2.0.0.
* <a href="#04:59.23" id="04:59.23">04:59.23 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: rouilj: I guess overall I don't understand why you think sorting by id might help. If there's a duplicated username+is retired in the CSV, no matter what the order, isn't that always going to cause a problem?
* <a href="#11:10.44" id="11:10.44">11:10.44 (EDT)</a> - __[rouilj](https://github.com/rouilj)__: Here's the joke. The import happens in two steps. Import the user and create the entry. Then in a second step retire the user. If the retired user comes in, it adds the user and the database creates the unique index key "username, 0". Then the loader checks to see if the newly added user is retired. If so it updates the index to "username, id". Then it loads the next user. If the non-retired user loads first, it never "clears" the
* <a href="#11:10.44" id="11:10.44">11:10.44 (EDT)</a> - __[rouilj](https://github.com/rouilj)__: name, 0" entry (since the user is not retired this is valid. So the next attempt to load a retired user with a duplicate name fails as the index entry is already in use and thus not unique.
* <a href="#11:11.13" id="11:11.13">11:11.13 (EDT)</a> - __[rouilj](https://github.com/rouilj)__: Does that make sense?
* <a href="#11:13.57" id="11:13.57">11:13.57 (EDT)</a> - __[rouilj](https://github.com/rouilj)__: As far as the key error, that looks ok. It's a timestamp with 11.8599999 seconds. The error message makes it sound like it's not being interpreted as a serilaized date. What column is it in? What's the header for that column?
* <a href="#11:16.00" id="11:16.00">11:16.00 (EDT)</a> - __[rouilj](https://github.com/rouilj)__: To speed things up you can copy the user.csv and user-journals.csv into a new directory and try importing that directory.
* <a href="#11:18.13" id="11:18.13">11:18.13 (EDT)</a> - __[rouilj](https://github.com/rouilj)__: Also "sorting by id" was a bad assumption. I assumed the non-retired user was the user with the highest ID. If that's not true, the import will fail as soon as a non-retired user is imported after a retired user with the same username.
* <a href="#11:53.18" id="11:53.18">11:53.18 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: rouilj: I see, thanks (re the import explanation)
* <a href="#11:53.33" id="11:53.33">11:53.33 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: ignore the KeyError, that was me forgetting about the header row when I sorted by user id
* <a href="#11:53.53" id="11:53.53">11:53.53 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: I have a script now that munges usernames, I was about to try it for real
* <a href="#11:56.55" id="11:56.55">11:56.55 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: hmph, the UNIQUE constraint still failed :-( I'll investigate some more. I guess I'm also going to want to tweak the roundup code itself to print out what wasn't UNIQUE otherwise the detective work will be painful.
* <a href="#11:58.00" id="11:58.00">11:58.00 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: going back to the import explanation, I understand what you meant now about sorting things so that non-retired entries are after all retired entries. I should try that too.
* <a href="#11:58.09" id="11:58.09">11:58.09 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: though if I really have made usernames unique, clearly something else is going on
* <a href="#12:07.27" id="12:07.27">12:07.27 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: running roundup-admin with -V got me as far as some output saying "Importing user - 432" just before it crashed. But user 432 doesn't look problematic at all, neither does anything around line 432 in the csv file
* <a href="#12:07.51" id="12:07.51">12:07.51 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: if I could get access to wherever log_debug goes then I could see the actual SQL that is failing
* <a href="#12:49.27" id="12:49.27">12:49.27 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: does roundup-admin respect LOGGING_LEVEL=DEBUG as described here? <https://roundup.sourceforge.io/docs/debugging.html> (I suspect not from observation)
* <a href="#12:49.41" id="12:49.41">12:49.41 (EDT)</a> - __[rouilj](https://github.com/rouilj)__: in your config.ini what is the [logging] filename setting? Also you should be able to set level to debug in [logging]. Maybe also try setting LOGGING_LEVEL=DEBUG in the environment. I use a [logging] config.
* <a href="#12:52.28" id="12:52.28">12:52.28 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: [back in a bit, need to turn off our power for a bit]
* <a href="#12:52.29" id="12:52.29">12:52.29 (EDT)</a> - __[rouilj](https://github.com/rouilj)__: I a rying to come up with a minimal logging config file for your needs. But yeah I am not sure about LOGGING_LEVEL, but the string is used in the configuration.py code in init_logging.
* <a href="#12:52.36" id="12:52.36">12:52.36 (EDT)</a> - __[rouilj](https://github.com/rouilj)__: ack
* <a href="#12:52.45" id="12:52.45">12:52.45 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: I did try setting LOGGING_LEVEL=DEBUG, it didn't help. I suspect roundup-admin isn't respecting it, but I'm not sure.
* <a href="#12:53.19" id="12:53.19">12:53.19 (EDT)</a> - __[rouilj](https://github.com/rouilj)__: possible. The invocation in configuration.py looks suspect.
* <a href="#12:53.41" id="12:53.41">12:53.41 (EDT)</a> - __[Heffalump](https://github.com/Heffalump)__: I should probably just hack the code locally to print, rather than wasting ages trying to understand the logging config :-)
* <a href="#12:54.26" id="12:54.26">12:54.26 (EDT)</a> - __[rouilj](https://github.com/rouilj)__: you could. I have a logging config that dumps what you want (and more). trimming it as we speak ummm type.
* <a href="#12:54.50" id="12:54.50">12:54.50 (EDT)</a> - __[rouilj](https://github.com/rouilj)__: he debugging.txt could use an overhaul with some logging.ini examples.
